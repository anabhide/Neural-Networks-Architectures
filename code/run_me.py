# -*- coding: utf-8 -*-
"""689 Assignment 4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uo_0gNW7GKz5FwvHh_hk51nwUOn_a8y6
"""

import time
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from utils import get_cifar10_loaders, SGD as CustomSGD, SGDMomentum as CustomSGDMomentum, Adam as CustomAdam, custom_glogot_normal
import torchvision
import torchvision.transforms as transforms

# set device and get loaders
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.backends.cudnn.benchmark = True

# use this when the dataset downloaded is the current directory
# I have used this for all the individual scripts !
# trainloader, testloader = get_cifar10_loaders(batch_size=512, num_workers=8)

transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(
    train_dataset,
    batch_size=512,
    shuffle=True,
    num_workers=8,
    pin_memory=True,
    persistent_workers=True
)

test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(
    test_dataset,
    batch_size=512,
    shuffle=False,
    num_workers=8,
    pin_memory=True,
    persistent_workers=True
)

# Single Layer Perceptron

# single-layer perceptron architecture
class SingleLayerPerceptron(nn.Module):
    def __init__(self):
        super(SingleLayerPerceptron, self).__init__()
        self.fc = nn.Linear(32 * 32, 10)

    def forward(self, x):
        x = x.view(x.size(0), -1)
        return self.fc(x)


# compute the misclassified fraction of images
def single_layer_perceptron_compute_error(model, dataloader):
    model.eval()
    total = 0
    incorrect = 0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            incorrect += (predicted != labels).sum().item()

    return incorrect / total  # fraction of wrongly classified examples


# compute loss for a specific loader using the loss function
def single_layer_perceptron_compute_loss(model, dataloader, loss_function):
    model.eval()
    total_loss = 0.0
    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            loss = loss_function(outputs, labels)
            total_loss += loss.item()
    return total_loss / len(dataloader)


# train the model
def single_layer_perceptron_train_model(model, optimizer, loss_function, trainloader, testloader, num_epochs=20):
    model.train()
    losses = []
    train_errors = []
    test_losses = []
    test_errors = []

    for epoch in range(num_epochs):
        current_loss = 0.0
        for images, labels in trainloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)

            optimizer.zero_grad()
            outputs = model(images)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()

            current_loss += loss.item()

        epoch_loss = current_loss / len(trainloader)
        losses.append(epoch_loss)

        # evaluate after each epoch
        train_error = single_layer_perceptron_compute_error(model, trainloader)
        test_error = single_layer_perceptron_compute_error(model, testloader)
        test_loss = single_layer_perceptron_compute_loss(model, testloader, loss_function)

        train_errors.append(train_error)
        test_errors.append(test_error)
        test_losses.append(test_loss)

        print(f"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} | Train Error: {train_error:.4f} | Test Error: {test_error:.4f}")

    return losses, train_errors, test_losses, test_errors


# function to plot the results
def single_layer_perceptron_plot_results(best_results):
    # Training Loss
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Single Layer Perceptron Training Loss per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Test Loss
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Single Layer Perceptron Test Loss per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Training Error
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["train_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Single Layer Perceptron Training Error per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Test Error
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Single Layer Perceptron Test Error per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()


# run everything together for this architecture
def single_layer_perceptron_run_experiments():
    loss_function = nn.CrossEntropyLoss()
    lr_options = {"SGD": [0.01, 0.05, 0.1], "SGD_momentum": [0.01, 0.05, 0.1], "Adam": [0.001, 0.005, 0.01]}
    best_results = {}

    for opt_name, lrs in lr_options.items():
        print(f"\n{opt_name}")
        best_acc = 0
        best_lr = None
        best_losses = []
        best_train_errors = []
        best_test_losses = []
        best_test_errors = []

        for lr in lrs:
            print(f"Currently using LR = {lr}")
            model = SingleLayerPerceptron().to(device)

            # use custom optimizers from utils
            if opt_name == "SGD":
                optimizer = CustomSGD(model.parameters(), lr=lr)
            elif opt_name == "SGD_momentum":
                optimizer = CustomSGDMomentum(model.parameters(), lr=lr, beta=0.1)
            elif opt_name == "Adam":
                optimizer = CustomAdam(model.parameters(), lr=lr, beta1=0.1, beta2=0.99)
            else:
                raise ValueError(f"Unknown optimizer: {opt_name}")

            start = time.time()
            losses, train_errors, test_losses, test_errors = single_layer_perceptron_train_model(
                model, optimizer, loss_function, trainloader, testloader)
            acc = 100 * (1 - test_errors[-1])
            end = time.time()

            print(f"LR = {lr} | Test Accuracy: {acc:.2f}% | Time: {end - start:.2f}s")

            if acc > best_acc:
                best_acc = acc
                best_lr = lr
                best_losses = losses
                best_train_errors = train_errors
                best_test_losses = test_losses
                best_test_errors = test_errors

        print(f"\nBest LR for {opt_name} is {best_lr} (Acc={best_acc:.2f}%)")
        best_results[opt_name] = {
            "best_lr": best_lr,
            "best_acc": best_acc,
            "losses": best_losses,
            "train_errors": best_train_errors,
            "test_losses": best_test_losses,
            "test_errors": best_test_errors
        }

    # plot all figures
    single_layer_perceptron_plot_results(best_results)
    return best_results


print("Running Single-Layer Perceptron")
results = single_layer_perceptron_run_experiments()
for k, v in results.items():
  print(f"{k}: best_lr={v['best_lr']}, best_acc={v['best_acc']:.2f}%")

# Shallow MLP

# shallow MLP architecture
class ShallowMLP(nn.Module):
    def __init__(self):
        super(ShallowMLP, self).__init__()
        self.fc1 = nn.Linear(32 * 32, 128)
        self.fc2 = nn.Linear(128, 10)
        self.activation = nn.Tanh()  # tanh activation

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = self.activation(self.fc1(x))  # hidden activation layer
        x = self.fc2(x)
        return x


# compute the misclassified fraction of images
def shallow_mlp_compute_error(model, dataloader):
    model.eval()
    total = 0
    incorrect = 0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            incorrect += (predicted != labels).sum().item()

    return incorrect / total  # fraction of wrongly classified examples


# compute loss for a specific loader using the loss function
def shallow_mlp_compute_loss(model, dataloader, loss_function):
    model.eval()
    total_loss = 0.0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            loss = loss_function(outputs, labels)
            total_loss += loss.item()

    return total_loss / len(dataloader)


# train the model
def shallow_mlp_train_model(model, optimizer, loss_function, trainloader, testloader, num_epochs=20):
    model.train()
    losses = []
    train_errors = []
    test_losses = []
    test_errors = []

    for epoch in range(num_epochs):
        current_loss = 0.0
        for images, labels in trainloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)

            optimizer.zero_grad()
            outputs = model(images)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()

            current_loss += loss.item()

        epoch_loss = current_loss / len(trainloader)
        losses.append(epoch_loss)

        # training and test errors/losses for this epoch
        train_error = shallow_mlp_compute_error(model, trainloader)
        test_error = shallow_mlp_compute_error(model, testloader)
        test_loss = shallow_mlp_compute_loss(model, testloader, loss_function)

        train_errors.append(train_error)
        test_errors.append(test_error)
        test_losses.append(test_loss)

        print(f"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} | Train Error: {train_error:.4f} | Test Error: {test_error:.4f}")

    return losses, train_errors, test_losses, test_errors


# function to plot the results
def shallow_mlp_plot_results(best_results):
    # Training Loss
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Shallow MLP Training Loss per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Test Loss
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Shallow MLP Test Loss per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Training Error
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["train_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Shallow MLP Training Error per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Test Error
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Shallow MLP Test Error per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()


# run everything together for this architecture
def shallow_mlp_run_experiments():
    loss_function = nn.CrossEntropyLoss()
    lr_options = {"SGD": [0.01, 0.05, 0.1], "SGD_momentum": [0.01, 0.05, 0.1], "Adam": [0.001, 0.005, 0.01]}
    best_results = {}

    for opt_name, lrs in lr_options.items():
        print(f"\n{opt_name}")
        best_acc = 0
        best_lr = None
        best_losses = []
        best_train_errors = []
        best_test_losses = []
        best_test_errors = []

        for lr in lrs:
            print(f"Currently using LR = {lr}")
            model = ShallowMLP().to(device)

            if opt_name == "SGD":
                optimizer = CustomSGD(model.parameters(), lr=lr)
            elif opt_name == "SGD_momentum":
                optimizer = CustomSGDMomentum(model.parameters(), lr=lr, beta=0.1)
            elif opt_name == "Adam":
                optimizer = CustomAdam(model.parameters(), lr=lr, beta1=0.1, beta2=0.99)
            else:
                raise ValueError(f"Unknown optimizer: {opt_name}")

            start = time.time()
            losses, train_errors, test_losses, test_errors = shallow_mlp_train_model(
                model, optimizer, loss_function, trainloader, testloader)
            acc = 100 * (1 - test_errors[-1])
            end = time.time()

            print(f"LR = {lr} | Test Accuracy: {acc:.2f}% | Time: {end - start:.2f}s")

            if acc > best_acc:
                best_acc = acc
                best_lr = lr
                best_losses = losses
                best_train_errors = train_errors
                best_test_losses = test_losses
                best_test_errors = test_errors

        print(f"\nBest LR for {opt_name} is {best_lr} (Acc={best_acc:.2f}%)")
        best_results[opt_name] = {
            "best_lr": best_lr,
            "best_acc": best_acc,
            "losses": best_losses,
            "train_errors": best_train_errors,
            "test_losses": best_test_losses,
            "test_errors": best_test_errors
        }

    # plot 4 separate figures
    shallow_mlp_plot_results(best_results)

    return best_results


print("Running Shallow MLP Architecture")
results = shallow_mlp_run_experiments()
for k, v in results.items():
    print(f"{k}: best_lr={v['best_lr']}, best_acc={v['best_acc']:.2f}%")

# Deep MLP

# deep MLP architecture
class DeepMLP(nn.Module):
    def __init__(self):
        super(DeepMLP, self).__init__()
        # 4 layers as required with the activation layer
        self.fc1 = nn.Linear(32 * 32, 128)
        self.fc2 = nn.Linear(128, 128)
        self.fc3 = nn.Linear(128, 128)
        self.fc4 = nn.Linear(128, 10)
        self.activation = nn.Tanh()


    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = self.activation(self.fc1(x))
        x = self.activation(self.fc2(x))
        x = self.activation(self.fc3(x))
        x = self.fc4(x)
        return x


# compute the misclassified fraction of images
def deep_mlp_compute_error(model, dataloader):
    model.eval()
    total = 0
    incorrect = 0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            incorrect += (predicted != labels).sum().item()

    return incorrect / total  # fraction of wrongly classified examples


# compute loss for a specific loader using the loss function
def deep_mlp_compute_loss(model, dataloader, loss_function):
    model.eval()
    total_loss = 0.0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            loss = loss_function(outputs, labels)
            total_loss += loss.item()

    return total_loss / len(dataloader)


# train the model
def deep_mlp_train_model(model, optimizer, loss_function, trainloader, testloader, num_epochs=20):
    model.train()
    losses = []
    train_errors = []
    test_losses = []
    test_errors = []

    for epoch in range(num_epochs):
        current_loss = 0.0
        for images, labels in trainloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)

            optimizer.zero_grad()
            outputs = model(images)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()

            current_loss += loss.item()

        epoch_loss = current_loss / len(trainloader)
        losses.append(epoch_loss)

        # training and test errors/losses for this epoch
        train_error = deep_mlp_compute_error(model, trainloader)
        test_error = deep_mlp_compute_error(model, testloader)
        test_loss = deep_mlp_compute_loss(model, testloader, loss_function)

        train_errors.append(train_error)
        test_errors.append(test_error)
        test_losses.append(test_loss)

        print(f"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} | Train Error: {train_error:.4f} | Test Error: {test_error:.4f}")

    return losses, train_errors, test_losses, test_errors


# plot results
def deep_mlp_plot_results(best_results):
    # Training Loss
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Deep MLP Training Loss per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Test Loss
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Deep MLP Test Loss per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Training Error
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["train_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Deep MLP Training Error per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Test Error
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Deep MLP Test Error per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()


# run everything together for this architecture
def deep_mlp_run_experiments():
    loss_function = nn.CrossEntropyLoss()
    lr_options = {"SGD": [0.01, 0.05, 0.1], "SGD_momentum": [0.01, 0.05, 0.1], "Adam": [0.001, 0.005, 0.01]}
    best_results = {}

    for opt_name, lrs in lr_options.items():
        print(f"\n{opt_name}")
        best_acc = 0
        best_lr = None
        best_losses = []
        best_train_errors = []
        best_test_losses = []
        best_test_errors = []

        for lr in lrs:
            print(f"Currently using LR = {lr}")
            model = DeepMLP().to(device)

            # use custom optimizers defined
            if opt_name == "SGD":
                optimizer = CustomSGD(model.parameters(), lr=lr)
            elif opt_name == "SGD_momentum":
                optimizer = CustomSGDMomentum(model.parameters(), lr=lr, beta=0.1)
            elif opt_name == "Adam":
                optimizer = CustomAdam(model.parameters(), lr=lr, beta1=0.1, beta2=0.99)
            else:
                raise ValueError(f"Unknown optimizer: {opt_name}")

            start = time.time()
            losses, train_errors, test_losses, test_errors = deep_mlp_train_model(
                model, optimizer, loss_function, trainloader, testloader)
            acc = 100 * (1 - test_errors[-1])
            end = time.time()

            print(f"LR = {lr} | Test Accuracy: {acc:.2f}% | Time: {end - start:.2f}s")

            if acc > best_acc:
                best_acc = acc
                best_lr = lr
                best_losses = losses
                best_train_errors = train_errors
                best_test_losses = test_losses
                best_test_errors = test_errors

        print(f"\nBest LR for {opt_name} is {best_lr} (Acc={best_acc:.2f}%)")
        best_results[opt_name] = {
            "best_lr": best_lr,
            "best_acc": best_acc,
            "losses": best_losses,
            "train_errors": best_train_errors,
            "test_losses": best_test_losses,
            "test_errors": best_test_errors
        }

    # plot 4 separate figures
    deep_mlp_plot_results(best_results)

    return best_results


print("Running Deep MLP Architecture")
results = deep_mlp_run_experiments()
for k, v in results.items():
    print(f"{k}: best_lr={v['best_lr']}, best_acc={v['best_acc']:.2f}%")

# Deep MLP with ReLU

# Deep MLP with ReLU architecture
class DeepMLPReLU(nn.Module):
    def __init__(self):
        super(DeepMLPReLU, self).__init__()
        self.fc1 = nn.Linear(32 * 32, 128)
        self.fc2 = nn.Linear(128, 128)
        self.fc3 = nn.Linear(128, 128)
        self.fc4 = nn.Linear(128, 10)
        self.activation = nn.ReLU()  # using ReLU activation

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = self.activation(self.fc1(x))
        x = self.activation(self.fc2(x))
        x = self.activation(self.fc3(x))
        x = self.activation(self.fc4(x))
        return x


# calculate fraction of incorrect predictions
def deep_mlp_relu_compute_error(model, dataloader):
    model.eval()
    total = 0
    incorrect = 0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            incorrect += (predicted != labels).sum().item()

    return incorrect / total  # fraction of wrongly classified examples


# calculate loss over a dataloader (train/test)
def deep_mlp_relu_compute_loss(model, dataloader, loss_function):
    model.eval()
    total_loss = 0.0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            loss = loss_function(outputs, labels)
            total_loss += loss.item()

    return total_loss / len(dataloader)


# train the model
def deep_mlp_relu_train_model(model, optimizer, loss_function, trainloader, testloader, num_epochs=20):
    model.train()
    losses = []
    train_errors = []
    test_losses = []
    test_errors = []

    for epoch in range(num_epochs):
        current_loss = 0.0
        for images, labels in trainloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)

            optimizer.zero_grad()
            outputs = model(images)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()

            current_loss += loss.item()

        epoch_loss = current_loss / len(trainloader)
        losses.append(epoch_loss)

        train_error = deep_mlp_relu_compute_error(model, trainloader)
        test_error = deep_mlp_relu_compute_error(model, testloader)
        test_loss = deep_mlp_relu_compute_loss(model, testloader, loss_function)

        train_errors.append(train_error)
        test_errors.append(test_error)
        test_losses.append(test_loss)

        print(f"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} | Train Error: {train_error:.4f} | Test Error: {test_error:.4f}")

    return losses, train_errors, test_losses, test_errors


# plot figures
def deep_mlp_relu_plot_results(best_results):
    # Training Loss
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Training Loss per Epoch for Deep MLP using ReLU")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Test Loss
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Test Loss per Epoch for Deep MLP using ReLU")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Training Error
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["train_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Training Error per Epoch for Deep MLP using ReLU")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Test Error
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Test Error per Epoch for Deep MLP using ReLU")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()


# run experiment for this architecture
def deep_mlp_relu_run_experiments():
    loss_function = nn.CrossEntropyLoss()
    lr_options = {"SGD": [0.01, 0.05, 0.1], "SGD_momentum": [0.01, 0.05, 0.1], "Adam": [0.001, 0.005, 0.01]}
    best_results = {}

    for opt_name, lrs in lr_options.items():
        print(f"\n{opt_name}")
        best_acc = 0
        best_lr = None
        best_losses = []
        best_train_errors = []
        best_test_losses = []
        best_test_errors = []

        for lr in lrs:
            print(f"Currently using LR = {lr}")
            model = DeepMLPReLU().to(device)

            # use custom optimizers from utils
            if opt_name == "SGD":
                optimizer = CustomSGD(model.parameters(), lr=lr)
            elif opt_name == "SGD_momentum":
                optimizer = CustomSGDMomentum(model.parameters(), lr=lr, beta=0.1)
            elif opt_name == "Adam":
                optimizer = CustomAdam(model.parameters(), lr=lr, beta1=0.1, beta2=0.99)
            else:
                raise ValueError(f"Unknown optimizer: {opt_name}")

            start = time.time()
            losses, train_errors, test_losses, test_errors = deep_mlp_relu_train_model(
                model, optimizer, loss_function, trainloader, testloader
            )
            acc = 100 * (1 - test_errors[-1])
            end = time.time()

            print(f"LR = {lr} | Test Accuracy: {acc:.2f}% | Time: {end - start:.2f}s")

            if acc > best_acc:
                best_acc = acc
                best_lr = lr
                best_losses = losses
                best_train_errors = train_errors
                best_test_losses = test_losses
                best_test_errors = test_errors

        print(f"\nBest LR for {opt_name} is {best_lr} (Acc={best_acc:.2f}%)")
        best_results[opt_name] = {
            "best_lr": best_lr,
            "best_acc": best_acc,
            "losses": best_losses,
            "train_errors": best_train_errors,
            "test_losses": best_test_losses,
            "test_errors": best_test_errors
        }

    # plot 4 separate figures
    deep_mlp_relu_plot_results(best_results)

    return best_results


print("Running Deep MLP with ReLU Architecture")
results = deep_mlp_relu_run_experiments()
for k, v in results.items():
    print(f"{k}: best_lr={v['best_lr']}, best_acc={v['best_acc']:.2f}%")

# CNN

# CNN Architecture
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(2, 2)

        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(2, 2)

        self.flatten = nn.Flatten()
        self.fc = nn.Linear(64 * 8 * 8, 10)

        # custom Glogot/ Xavier initialization
        custom_glogot_normal(self.conv1.weight)
        custom_glogot_normal(self.conv2.weight)
        custom_glogot_normal(self.fc.weight)

        if self.conv1.bias is not None:
            nn.init.zeros_(self.conv1.bias)
        if self.conv2.bias is not None:
            nn.init.zeros_(self.conv2.bias)
        if self.fc.bias is not None:
            nn.init.zeros_(self.fc.bias)


    def forward(self, x):
        x = self.pool1(self.relu1(self.conv1(x)))
        x = self.pool2(self.relu2(self.conv2(x)))
        x = self.flatten(x)
        x = self.fc(x)
        return x


# calculate fraction of incorrect predictions
def cnn_compute_error(model, dataloader):
    model.eval()
    total = 0
    incorrect = 0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            incorrect += (predicted != labels).sum().item()

    return incorrect / total


# calculate loss over a dataloader (train/test)
def cnn_compute_loss(model, dataloader, loss_function):
    model.eval()
    total_loss = 0.0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            loss = loss_function(outputs, labels)
            total_loss += loss.item()

    return total_loss / len(dataloader)


# train the model
def cnn_train_model(model, optimizer, loss_function, trainloader, testloader, num_epochs=20):
    losses, train_errors, test_losses, test_errors = [], [], [], []

    for epoch in range(num_epochs):
        model.train()
        current_loss = 0.0
        for images, labels in trainloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)

            optimizer.zero_grad()
            outputs = model(images)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()

            current_loss += loss.item()

        epoch_loss = current_loss / len(trainloader)
        losses.append(epoch_loss)

        train_error = cnn_compute_error(model, trainloader)
        test_error = cnn_compute_error(model, testloader)
        test_loss = cnn_compute_loss(model, testloader, loss_function)

        train_errors.append(train_error)
        test_errors.append(test_error)
        test_losses.append(test_loss)

        print(f"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} | Train Error: {train_error:.4f} | Test Error: {test_error:.4f}")

    return losses, train_errors, test_losses, test_errors


# plot the results
def cnn_plot_results(best_results):
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Training Loss per Epoch for CNN")
    plt.xlabel("Epoch"); plt.ylabel("Loss")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Test Loss per Epoch for CNN")
    plt.xlabel("Epoch"); plt.ylabel("Loss")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["train_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Training Error per Epoch for CNN")
    plt.xlabel("Epoch"); plt.ylabel("Error")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Test Error per Epoch for CNN")
    plt.xlabel("Epoch"); plt.ylabel("Error")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()


# run the experiments for this script
def cnn_run_experiments():
    loss_function = nn.CrossEntropyLoss()
    lr_options = {"SGD": [0.01, 0.05, 0.1], "SGD_momentum": [0.01, 0.05, 0.1], "Adam": [0.001, 0.005, 0.01]}
    best_results = {}

    for opt_name, lrs in lr_options.items():
        print(f"\n{opt_name}")
        best_acc, best_lr = 0, None
        best_losses, best_train_errors, best_test_losses, best_test_errors = [], [], [], []

        for lr in lrs:
            print(f"Currently using LR = {lr}")
            model = CNN().to(device)

            if opt_name == "SGD":
                optimizer = CustomSGD(model.parameters(), lr=lr)
            elif opt_name == "SGD_momentum":
                optimizer = CustomSGDMomentum(model.parameters(), lr=lr, beta=0.1)
            elif opt_name == "Adam":
                optimizer = CustomAdam(model.parameters(), lr=lr, beta1=0.1, beta2=0.99)

            start = time.time()
            losses, train_errors, test_losses, test_errors = cnn_train_model(
                model, optimizer, loss_function, trainloader, testloader
            )
            acc = 100 * (1 - test_errors[-1])
            end = time.time()

            print(f"LR = {lr} | Test Accuracy: {acc:.2f}% | Time: {end-start:.2f}s")

            if acc > best_acc:
                best_acc, best_lr = acc, lr
                best_losses, best_train_errors, best_test_losses, best_test_errors = losses, train_errors, test_losses, test_errors

        print(f"\nBest LR for {opt_name} is {best_lr} (Acc={best_acc:.2f}%)")
        best_results[opt_name] = {
            "best_lr": best_lr, "best_acc": best_acc,
            "losses": best_losses, "train_errors": best_train_errors,
            "test_losses": best_test_losses, "test_errors": best_test_errors
        }

    cnn_plot_results(best_results)
    return best_results


print("Running CNN Architecture")
results = cnn_run_experiments()
for k, v in results.items():
    print(f"{k}: best_lr={v['best_lr']}, best_acc={v['best_acc']:.2f}%")

# CNN Dropout

# CNN with Dropout architecture
class CNN_Dropout(nn.Module):
    def __init__(self):
        super(CNN_Dropout, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(2, 2)

        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(2, 2)

        self.flatten = nn.Flatten()
        self.dropout = nn.Dropout(p=0.5)
        self.fc = nn.Linear(64 * 8 * 8, 10)

        # Xavier (Glorot) initialization for conv + fc
        custom_glogot_normal(self.conv1.weight)
        if self.conv1.bias is not None:
            nn.init.zeros_(self.conv1.bias)
        custom_glogot_normal(self.conv2.weight)
        if self.conv2.bias is not None:
            nn.init.zeros_(self.conv2.bias)
        custom_glogot_normal(self.fc.weight)
        if self.fc.bias is not None:
            nn.init.zeros_(self.fc.bias)


    def forward(self, x):
        x = self.pool1(self.relu1(self.conv1(x)))
        x = self.pool2(self.relu2(self.conv2(x)))
        x = self.flatten(x)
        x = self.dropout(x)
        x = self.fc(x)
        return x



# calculate fraction of incorrect predictions
def cnn_dropout_compute_error(model, dataloader):
    model.eval()
    total = 0
    incorrect = 0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            incorrect += (predicted != labels).sum().item()

    return incorrect / total  # fraction of wrongly classified examples


# calculate loss over a dataloader (train/test)
def cnn_dropout_compute_loss(model, dataloader, loss_function):
    model.eval()
    total_loss = 0.0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            loss = loss_function(outputs, labels)
            total_loss += loss.item()

    return total_loss / len(dataloader)


# train the model
def cnn_dropout_train_model(model, optimizer, loss_function, trainloader, testloader, num_epochs=20):
    model.train()
    losses = []
    train_errors = []
    test_losses = []
    test_errors = []

    for epoch in range(num_epochs):
        current_loss = 0.0
        for images, labels in trainloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)

            optimizer.zero_grad()
            outputs = model(images)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()

            current_loss += loss.item()

        epoch_loss = current_loss / len(trainloader)
        losses.append(epoch_loss)

        train_error = cnn_dropout_compute_error(model, trainloader)
        test_error = cnn_dropout_compute_error(model, testloader)
        test_loss = cnn_dropout_compute_loss(model, testloader, loss_function)

        train_errors.append(train_error)
        test_errors.append(test_error)
        test_losses.append(test_loss)

        print(f"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} | Train Error: {train_error:.4f} | Test Error: {test_error:.4f}")

    return losses, train_errors, test_losses, test_errors


# plot figures
def cnn_dropout_plot_results(best_results):
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Training Loss per Epoch for CNN with Dropout")
    plt.xlabel("Epoch"); plt.ylabel("Loss")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Test Loss per Epoch for CNN with Dropout")
    plt.xlabel("Epoch"); plt.ylabel("Loss")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["train_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Training Error per Epoch for CNN with Dropout")
    plt.xlabel("Epoch"); plt.ylabel("Error")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Test Error per Epoch for CNN with Dropout")
    plt.xlabel("Epoch"); plt.ylabel("Error")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()


# run experiment for this architecture
def cnn_dropout_run_experiments():
    loss_function = nn.CrossEntropyLoss()
    lr_options = {"SGD": [0.01, 0.05, 0.1], "SGD_momentum": [0.01, 0.05, 0.1], "Adam": [0.001, 0.005, 0.01]}
    best_results = {}

    for opt_name, lrs in lr_options.items():
        print(f"\n{opt_name}")
        best_acc = 0
        best_lr = None
        best_losses = []
        best_train_errors = []
        best_test_losses = []
        best_test_errors = []

        for lr in lrs:
            print(f"Currently using LR = {lr}")
            model = CNN_Dropout().to(device)

            if opt_name == "SGD":
                optimizer = CustomSGD(model.parameters(), lr=lr)
            elif opt_name == "SGD_momentum":
                optimizer = CustomSGDMomentum(model.parameters(), lr=lr, beta=0.1)
            elif opt_name == "Adam":
                optimizer = CustomAdam(model.parameters(), lr=lr, beta1=0.1, beta2=0.99)

            start = time.time()
            losses, train_errors, test_losses, test_errors = cnn_dropout_train_model(
                model, optimizer, loss_function, trainloader, testloader
            )

            acc = 100 * (1 - test_errors[-1])
            end = time.time()

            print(f"LR = {lr} | Test Accuracy: {acc:.2f}% | Time: {end - start:.2f}s")

            if acc > best_acc:
                best_acc = acc
                best_lr = lr
                best_losses = losses
                best_train_errors = train_errors
                best_test_losses = test_losses
                best_test_errors = test_errors

        print(f"\nBest LR for {opt_name} is {best_lr} (Acc={best_acc:.2f}%)")
        best_results[opt_name] = {
            "best_lr": best_lr,
            "best_acc": best_acc,
            "losses": best_losses,
            "train_errors": best_train_errors,
            "test_losses": best_test_losses,
            "test_errors": best_test_errors
        }

    cnn_dropout_plot_results(best_results)
    return best_results


print("Running CNN with Dropout (p=0.5) Architecture")
results = cnn_dropout_run_experiments()
for k, v in results.items():
    print(f"{k}: best_lr={v['best_lr']}, best_acc={v['best_acc']:.2f}%")

# Deep CNN

# Deep CNN (VGG-style) architecture
class DeepCNN(nn.Module):
    def __init__(self):
        super(DeepCNN, self).__init__()

        # first block
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)
        self.pool1 = nn.MaxPool2d(2, 2)

        # second block
        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.pool2 = nn.MaxPool2d(2, 2)

        self.flatten = nn.Flatten()
        self.dropout = nn.Dropout(p=0.5)
        self.fc = nn.Linear(64 * 8 * 8, 10)

        self.relu = nn.ReLU()

        # Glorot / Xavier initialization for weights and zero biases
        for layer in [self.conv1, self.conv2, self.conv3, self.conv4, self.fc]:
            custom_glogot_normal(layer.weight)
            if layer.bias is not None:
                nn.init.zeros_(layer.bias)


    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.pool1(x)

        x = self.relu(self.conv3(x))
        x = self.relu(self.conv4(x))
        x = self.pool2(x)

        x = self.flatten(x)
        x = self.dropout(x)
        x = self.fc(x)
        return x


# compute fraction of incorrect predictions
def deep_cnn_compute_error(model, dataloader):
    model.eval()
    total = 0
    incorrect = 0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            incorrect += (predicted != labels).sum().item()

    return incorrect / total


# compute loss over a dataloader
def deep_cnn_compute_loss(model, dataloader, loss_function):
    model.eval()
    total_loss = 0.0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            loss = loss_function(outputs, labels)
            total_loss += loss.item()

    return total_loss / len(dataloader)


# train the model
def deep_cnn_train_model(model, optimizer, loss_function, trainloader, testloader, num_epochs=20):
    losses, train_errors, test_losses, test_errors = [], [], [], []

    for epoch in range(num_epochs):
        model.train()
        current_loss = 0.0
        for images, labels in trainloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            optimizer.zero_grad()
            outputs = model(images)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()
            current_loss += loss.item()

        epoch_loss = current_loss / len(trainloader)
        losses.append(epoch_loss)

        train_errors.append(deep_cnn_compute_error(model, trainloader))
        test_errors.append(deep_cnn_compute_error(model, testloader))
        test_losses.append(deep_cnn_compute_loss(model, testloader, loss_function))

        print(f"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} | "
              f"Train Error: {train_errors[-1]:.4f} | Test Error: {test_errors[-1]:.4f}")

    return losses, train_errors, test_losses, test_errors


# plot results
def deep_cnn_plot_results(best_results):
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Training Loss per Epoch for Deep CNN (VGG-style)")
    plt.xlabel("Epoch"); plt.ylabel("Loss")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Test Loss per Epoch for Deep CNN (VGG-style)")
    plt.xlabel("Epoch"); plt.ylabel("Loss")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["train_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Training Error per Epoch for Deep CNN (VGG-style)")
    plt.xlabel("Epoch"); plt.ylabel("Error")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Test Error per Epoch for Deep CNN (VGG-style)")
    plt.xlabel("Epoch"); plt.ylabel("Error")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()


# run experiments
def deep_cnn_run_experiments():
    loss_function = nn.CrossEntropyLoss()
    lr_options = {"SGD": [0.01, 0.05, 0.1],
                  "SGD_momentum": [0.01, 0.05, 0.1],
                  "Adam": [0.001, 0.005, 0.01]}
    best_results = {}

    for opt_name, lrs in lr_options.items():
        print(f"\n{opt_name}")
        best_acc, best_lr = 0, None
        best_losses, best_train_errors, best_test_losses, best_test_errors = [], [], [], []

        for lr in lrs:
            print(f"Currently using LR = {lr}")
            model = DeepCNN().to(device)

            if opt_name == "SGD":
                optimizer = CustomSGD(model.parameters(), lr=lr)
            elif opt_name == "SGD_momentum":
                optimizer = CustomSGDMomentum(model.parameters(), lr=lr, beta=0.1)
            elif opt_name == "Adam":
                optimizer = CustomAdam(model.parameters(), lr=lr, beta1=0.1, beta2=0.99)

            start = time.time()
            losses, train_errors, test_losses, test_errors = deep_cnn_train_model(
                model, optimizer, loss_function, trainloader, testloader
            )
            acc = 100 * (1 - test_errors[-1])
            end = time.time()
            print(f"LR = {lr} | Test Accuracy: {acc:.2f}% | Time: {end-start:.2f}s")

            if acc > best_acc:
                best_acc, best_lr = acc, lr
                best_losses, best_train_errors, best_test_losses, best_test_errors = losses, train_errors, test_losses, test_errors

        print(f"\nBest LR for {opt_name} is {best_lr} (Acc={best_acc:.2f}%)")
        best_results[opt_name] = {
            "best_lr": best_lr,
            "best_acc": best_acc,
            "losses": best_losses,
            "train_errors": best_train_errors,
            "test_losses": best_test_losses,
            "test_errors": best_test_errors
        }

    deep_cnn_plot_results(best_results)
    return best_results


print("Running Deep CNN (VGG-style) Architecture")
results = deep_cnn_run_experiments()
for k, v in results.items():
    print(f"{k}: best_lr={v['best_lr']}, best_acc={v['best_acc']:.2f}%")

# ResNet

# Residual Network (ResNet) architecture
class ResNet(nn.Module):
    def __init__(self):
        super(ResNet, self).__init__()
        # Layer 1 & 2
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)
        self.proj1 = nn.Conv2d(1, 32, kernel_size=1, stride=1, padding=0)
        self.pool1 = nn.MaxPool2d(2, 2)
        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.proj2 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0)
        self.pool2 = nn.MaxPool2d(2, 2)
        self.flatten = nn.Flatten()
        self.dropout = nn.Dropout(p=0.5)
        self.fc = nn.Linear(64 * 8 * 8, 10)

        # Glorot / Xavier initialization for the layers
        for layer in [self.conv1, self.conv2, self.proj1, self.conv3, self.conv4, self.proj2, self.fc]:
            custom_glogot_normal(layer.weight)
            if layer.bias is not None:
                nn.init.zeros_(layer.bias)


    def forward(self, x):
        # 1st residual block
        out = self.relu(self.conv1(x))
        out2 = self.conv2(out)
        proj_x = self.proj1(x)
        res1 = self.relu(out2 + proj_x)
        pooled = self.pool1(res1)

        # 2nd residual block
        out = self.relu(self.conv3(pooled))
        out2 = self.conv4(out)
        proj_pooled = self.proj2(pooled)
        res2 = self.relu(out2 + proj_pooled)
        out = self.pool2(res2)

        out = self.flatten(out)
        out = self.dropout(out)
        out = self.fc(out)

        return out



# calculate fraction of incorrect predictions
def resnet_compute_error(model, dataloader):
    model.eval()
    total = 0
    incorrect = 0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            incorrect += (predicted != labels).sum().item()

    return incorrect / total  # fraction of wrongly classified examples


# calculate loss over a dataloader (train/test)
def resnet_compute_loss(model, dataloader, loss_function):
    model.eval()
    total_loss = 0.0

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(images)
            loss = loss_function(outputs, labels)
            total_loss += loss.item()

    return total_loss / len(dataloader)


# train the model
def resnet_train_model(model, optimizer, loss_function, trainloader, testloader, num_epochs=20):
    model.train()
    losses = []
    train_errors = []
    test_losses = []
    test_errors = []

    for epoch in range(num_epochs):
        current_loss = 0.0
        for images, labels in trainloader:
            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)

            optimizer.zero_grad()

            outputs = model(images)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()

            current_loss += loss.item()

        epoch_loss = current_loss / len(trainloader)
        losses.append(epoch_loss)

        # training and test errors/losses for this epoch
        train_error = resnet_compute_error(model, trainloader)
        test_error = resnet_compute_error(model, testloader)
        test_loss = resnet_compute_loss(model, testloader, loss_function)

        train_errors.append(train_error)
        test_errors.append(test_error)
        test_losses.append(test_loss)

        print(f"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} | Train Error: {train_error:.4f} | Test Error: {test_error:.4f}")

    return losses, train_errors, test_losses, test_errors


# plot figures
def resnet_plot_results(best_results):
    # Training Loss
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Training Loss per Epoch for ResNet")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Test Loss
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_losses"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Test Loss per Epoch for ResNet")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Training Error
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["train_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Training Error per Epoch for ResNet")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Test Error
    plt.figure(figsize=(8,6))
    for name, res in best_results.items():
        plt.plot(res["test_errors"], label=f"{name} (lr={res['best_lr']})")
    plt.title("Test Error per Epoch for ResNet")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()


# run experiment for this architecture
def resnet_run_experiments():
    loss_function = nn.CrossEntropyLoss()
    lr_options = {"SGD": [0.01, 0.05, 0.1], "SGD_momentum": [0.01, 0.05, 0.1], "Adam": [0.001, 0.005, 0.01]}
    best_results = {}

    for opt_name, lrs in lr_options.items():
        print(f"\n{opt_name}")
        best_acc = 0
        best_lr = None
        best_losses = []
        best_train_errors = []
        best_test_losses = []
        best_test_errors = []

        for lr in lrs:
            print(f"Currently using LR = {lr}")
            model = ResNet().to(device)

            if opt_name == "SGD":
                optimizer = CustomSGD(model.parameters(), lr=lr)
            elif opt_name == "SGD_momentum":
                optimizer = CustomSGDMomentum(model.parameters(), lr=lr, beta=0.1)
            elif opt_name == "Adam":
                optimizer = CustomAdam(model.parameters(), lr=lr, beta1=0.1, beta2=0.99)

            start = time.time()
            # train (now tracks test metrics each epoch)
            losses, train_errors, test_losses, test_errors = resnet_train_model(
                model, optimizer, loss_function, trainloader, testloader
            )

            acc = 100 * (1 - test_errors[-1])
            end = time.time()

            print(f"LR = {lr} | Test Accuracy: {acc:.2f}% | Time: {end - start:.2f}s")

            if acc > best_acc:
                best_acc = acc
                best_lr = lr
                best_losses = losses
                best_train_errors = train_errors
                best_test_losses = test_losses
                best_test_errors = test_errors

        print(f"\nBest LR for {opt_name} is {best_lr} (Acc={best_acc:.2f}%)")
        best_results[opt_name] = {
            "best_lr": best_lr,
            "best_acc": best_acc,
            "losses": best_losses,
            "train_errors": best_train_errors,
            "test_losses": best_test_losses,
            "test_errors": best_test_errors
        }

    resnet_plot_results(best_results)

    return best_results


print("Running Residual Networks Architecture")
results = resnet_run_experiments()
for k, v in results.items():
    print(f"{k}: best_lr={v['best_lr']}, best_acc={v['best_acc']:.2f}%")